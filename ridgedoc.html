
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>linear_model.Ridge &#8212; Snap Machine Learning 1.0 documentation</title>
    <link rel="stylesheet" href="_static/nature.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" /> 
  </head><body>

<div style="background-color: white; text-align: left; padding: 10px 10px 15px 15px">
<a href="index.html"><h1 style="font-size: 3em;">Snap Machine Learning</h1></a>
</div>

    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li><a href="index.html">home</a>|&nbsp;</li>
        <li><a href="search.html">search</a>|&nbsp;</li>
 
      </ul>
    </div>

      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="linear-model-ridge">
<span id="ridge-doc"></span><h1>linear_model.Ridge<a class="headerlink" href="#linear-model-ridge" title="Permalink to this headline">¶</a></h1>
<dl class="class">
<dt id="pai4sk.linear_model.Ridge">
<em class="property">class </em><code class="descclassname">pai4sk.linear_model.</code><code class="descname">Ridge</code><span class="sig-paren">(</span><em>alpha=1.0</em>, <em>fit_intercept=True</em>, <em>normalize=False</em>, <em>copy_X=True</em>, <em>max_iter=None</em>, <em>tol=0.001</em>, <em>solver='auto'</em>, <em>random_state=None</em>, <em>dual=False</em>, <em>verbose=0</em>, <em>use_gpu=True</em>, <em>device_ids=[]</em>, <em>return_training_history=None</em>, <em>privacy=False</em>, <em>eta=0.3</em>, <em>batch_size=100</em>, <em>privacy_epsilon=10</em>, <em>grad_clip=1</em>, <em>num_threads=1</em><span class="sig-paren">)</span><a class="headerlink" href="#pai4sk.linear_model.Ridge" title="Permalink to this definition">¶</a></dt>
<dd><p>Linear least squares with l2 regularization.</p>
<p>Minimizes the objective function:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">||</span><span class="n">y</span> <span class="o">-</span> <span class="n">Xw</span><span class="o">||^</span><span class="mi">2_2</span> <span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="o">||</span><span class="n">w</span><span class="o">||^</span><span class="mi">2_2</span>
</pre></div>
</div>
<p>This model solves a regression model where the loss function is
the linear least squares function and regularization is given by
the l2-norm. Also known as Ridge Regression or Tikhonov regularization.
This estimator has built-in support for multi-variate regression
(i.e., when y is a 2d-array of shape [n_samples, n_targets]).</p>
<p>Read more in the <span class="xref std std-ref">User Guide</span>.</p>
<p>For SnapML solver this supports both local and distributed(MPI) method of execution.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>alpha</strong> (<em>{float</em><em>, </em><em>array-like}</em><em>, </em><em>shape</em><em> (</em><em>n_targets</em><em>)</em>) – Regularization strength; must be a positive float. Regularization
improves the conditioning of the problem and reduces the variance of
the estimates. Larger values specify stronger regularization.
Alpha corresponds to <code class="docutils literal notranslate"><span class="pre">C^-1</span></code> in other linear models such as
LogisticRegression or LinearSVC. If an array is passed, penalties are
assumed to be specific to the targets. Hence they must correspond in
number.</li>
<li><strong>fit_intercept</strong> (<em>boolean</em>) – Whether to calculate the intercept for this model. If set
to false, no intercept will be used in calculations
(e.g. data is expected to be already centered).</li>
<li><strong>normalize</strong> (<em>boolean</em><em>, </em><em>optional</em><em>, </em><em>default False</em>) – This parameter is ignored when <code class="docutils literal notranslate"><span class="pre">fit_intercept</span></code> is set to False.
If True, the regressors X will be normalized before regression by
subtracting the mean and dividing by the l2-norm.
If you wish to standardize, please use
<code class="xref py py-class docutils literal notranslate"><span class="pre">pai4sk.preprocessing.StandardScaler</span></code> before calling <code class="docutils literal notranslate"><span class="pre">fit</span></code>
on an estimator with <code class="docutils literal notranslate"><span class="pre">normalize=False</span></code>.</li>
<li><strong>copy_X</strong> (<em>boolean</em><em>, </em><em>optional</em><em>, </em><em>default True</em>) – If True, X will be copied; else, it may be overwritten.</li>
<li><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>optional</em>) – Maximum number of iterations for conjugate gradient solver.
For ‘sparse_cg’ and ‘lsqr’ solvers, the default value is determined
by scipy.sparse.linalg. For ‘sag’ solver, the default value is 1000.</li>
<li><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a>) – Precision of the solution.</li>
<li><strong>regularizer</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>default : 1.0</em>) – Regularization strength. It must be a positive float.
Larger regularization values imply stronger regularization.</li>
<li><strong>use_gpu</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>default : False</em>) – Flag for indicating the hardware platform used for training. If True, the training
is performed using the GPU. If False, the training is performed using the CPU.
Applicable only for snapml solver</li>
<li><strong>device_ids</strong> (<em>array-like of int</em><em>, </em><em>default :</em><em> [</em><em>]</em>) – If use_gpu is True, it indicates the IDs of the GPUs used for training.
For single GPU training, set device_ids to the GPU ID to be used for training, e.g., [0].
For multi-GPU training, set device_ids to a list of GPU IDs to be used for training, e.g., [0, 1].
Applicable only for snapml solver</li>
<li><strong>num_threads</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>default : 1</em>) – The number of threads used for running the training. The value of this parameter
should be a multiple of 32 if the training is performed on GPU (use_gpu=True)
(default value for GPU is 256). Applicable only for snapml solver</li>
<li><strong>return_training_history</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.7)"><em>None</em></a><em>, </em><em>default : None</em>) – How much information about the training should be collected and returned by the fit function. By
default no information is returned (None), but this parameter can be set to “summary”, to obtain
summary statistics at the end of training, or “full” to obtain a complete set of statistics
for the entire training procedure. Note, enabling either option will result in slower training.
Applicable only for snapml solver</li>
<li><strong>solver</strong> (<em>{'auto'</em><em>, </em><em>'svd'</em><em>, </em><em>'cholesky'</em><em>, </em><em>'lsqr'</em><em>, </em><em>'sparse_cg'</em><em>, </em><em>'sag'</em><em>, </em><em>'saga'</em><em>, </em><em>'snapml'}</em>) – <p>Solver to use in the computational routines:</p>
<ul>
<li>’auto’ chooses the solver automatically based on the type of data.</li>
<li>’svd’ uses a Singular Value Decomposition of X to compute the Ridge
coefficients. More stable for singular matrices than
‘cholesky’.</li>
<li>’cholesky’ uses the standard scipy.linalg.solve function to
obtain a closed-form solution.</li>
<li>’sparse_cg’ uses the conjugate gradient solver as found in
scipy.sparse.linalg.cg. As an iterative algorithm, this solver is
more appropriate than ‘cholesky’ for large-scale data
(possibility to set <cite>tol</cite> and <cite>max_iter</cite>).</li>
<li>’lsqr’ uses the dedicated regularized least-squares routine
scipy.sparse.linalg.lsqr. It is the fastest and uses an iterative
procedure.</li>
<li>’sag’ uses a Stochastic Average Gradient descent, and ‘saga’ uses
its improved, unbiased version named SAGA. Both methods also use an
iterative procedure, and are often faster than other solvers when
both n_samples and n_features are large. Note that ‘sag’ and
‘saga’ fast convergence is only guaranteed on features with
approximately the same scale. You can preprocess the data with a
scaler from pai4sk.preprocessing.</li>
</ul>
<p>All last five solvers support both dense and sparse data. However,
only ‘sag’ and ‘saga’ supports sparse input when <cite>fit_intercept</cite> is
True.</p>
<div class="versionadded">
<p><span class="versionmodified">New in version 0.17: </span>Stochastic Average Gradient descent solver.</p>
</div>
<div class="versionadded">
<p><span class="versionmodified">New in version 0.19: </span>SAGA solver.</p>
</div>
</li>
<li><strong>random_state</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>RandomState instance</em><em> or </em><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.7)"><em>None</em></a><em>, </em><em>optional</em><em>, </em><em>default None</em>) – <p>The seed of the pseudo random number generator to use when shuffling
the data.  If int, random_state is the seed used by the random number
generator; If RandomState instance, random_state is the random number
generator; If None, the random number generator is the RandomState
instance used by <cite>np.random</cite>. Used when <code class="docutils literal notranslate"><span class="pre">solver</span></code> == ‘sag’.</p>
<div class="versionadded">
<p><span class="versionmodified">New in version 0.17: </span><em>random_state</em> to support Stochastic Average Gradient.</p>
</div>
</li>
<li><strong>privacy</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>default : False</em>) – Train the model using a differentially private algorithm.</li>
<li><strong>eta</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>default : 0.3</em>) – Learning rate for the differentially private training algorithm.</li>
<li><strong>batch_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>default : 100</em>) – Mini-batch size for the differentially private training algorithm.</li>
<li><strong>privacy_epsilon</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>default : 10.0</em>) – Target privacy gaurantee. Learned model will be (privacy_epsilon, 0.01)-private.</li>
<li><strong>grad_clip</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>default: 1.0</em>) – Gradient clipping parameter for the differentially private training algorithm</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Variables:</th><td class="field-body"><ul class="first last simple">
<li><strong>coef</strong> (<em>array</em><em>, </em><em>shape</em><em> (</em><em>n_features</em><em>,</em><em>) or </em><em>(</em><em>n_targets</em><em>, </em><em>n_features</em><em>)</em>) – Weight vector(s).</li>
<li><strong>intercept</strong> (<em>float | array</em><em>, </em><em>shape =</em><em> (</em><em>n_targets</em><em>,</em><em>)</em>) – Independent term in decision function. Set to 0.0 if
<code class="docutils literal notranslate"><span class="pre">fit_intercept</span> <span class="pre">=</span> <span class="pre">False</span></code>.</li>
<li><strong>n_iter</strong> (<em>array</em><em> or </em><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.7)"><em>None</em></a><em>, </em><em>shape</em><em> (</em><em>n_targets</em><em>,</em><em>)</em>) – Actual number of iterations for each target. Available only for
sag and lsqr solvers. Other solvers will return None.</li>
<li><strong>training_history</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.7)"><em>dict</em></a>) – <p>It returns a dictionary with the following keys : ‘epochs’, ‘t_elap_sec’, ‘train_obj’.
If ‘return_training_history’ is set to “summary”, ‘epochs’ contains the total number of
epochs performed, ‘t_elap_sec’ contains the total time for completing all of those epochs.
If ‘return_training_history’ is set to “full”, ‘epochs’ indicates the number of epochs
that have elapsed so far, and ‘t_elap_sec’ contains the time to do those epochs.
‘train_obj’ is the training loss.
Applicable only for snapml solver.</p>
<div class="versionadded">
<p><span class="versionmodified">New in version 0.17.</span></p>
</div>
</li>
</ul>
</td>
</tr>
</tbody>
</table>
<div class="admonition seealso">
<p class="first admonition-title">See also</p>
<dl class="last docutils">
<dt><code class="xref py py-class docutils literal notranslate"><span class="pre">RidgeClassifier</span></code></dt>
<dd>Ridge classifier</dd>
<dt><code class="xref py py-class docutils literal notranslate"><span class="pre">RidgeCV</span></code></dt>
<dd>Ridge regression with built-in cross validation</dd>
<dt><code class="xref py py-class docutils literal notranslate"><span class="pre">pai4sk.kernel_ridge.KernelRidge</span></code></dt>
<dd>Kernel ridge regression combines ridge regression with the kernel trick</dd>
</dl>
</div>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pai4sk.linear_model</span> <span class="k">import</span> <span class="n">Ridge</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">Ridge</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="c1"># doctest: +NORMALIZE_WHITESPACE</span>
<span class="go">Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,</span>
<span class="go">      normalize=False, random_state=None, solver=&#39;auto&#39;, tol=0.001)</span>
</pre></div>
</div>
<dl class="method">
<dt id="pai4sk.linear_model.Ridge.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X</em>, <em>y</em>, <em>sample_weight=None</em><span class="sig-paren">)</span><a class="headerlink" href="#pai4sk.linear_model.Ridge.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit Ridge regression model</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>{array-like</em><em>, </em><em>sparse matrix}</em><em>, </em><em>shape =</em><em> [</em><em>n_samples</em><em>, </em><em>n_features</em><em>]</em>) – Training data
For SnapML solver it also supports input of types SnapML data partition and DeviceNDArray.</li>
<li><strong>y</strong> (<em>array-like</em><em>, </em><em>shape =</em><em> [</em><em>n_samples</em><em>] or </em><em>[</em><em>n_samples</em><em>, </em><em>n_targets</em><em>]</em>) – Target values</li>
<li><strong>sample_weight</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em> or </em><em>numpy array of shape</em><em> [</em><em>n_samples</em><em>]</em>) – Individual weights for each sample</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>self</strong></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">returns an instance of self.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pai4sk.linear_model.Ridge.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>X</em>, <em>num_threads=0</em><span class="sig-paren">)</span><a class="headerlink" href="#pai4sk.linear_model.Ridge.predict" title="Permalink to this definition">¶</a></dt>
<dd><blockquote>
<div><p>Class predictions
The returned class estimates.
Parameters
———-
X : sparse matrix (csr_matrix) or dense matrix (ndarray)</p>
<blockquote>
<div>Dataset used for predicting class estimates.
For SnapML solver it also supports input of type SnapML data partition.</div></blockquote>
</div></blockquote>
<dl class="docutils">
<dt>num_threads <span class="classifier-delimiter">:</span> <span class="classifier">int, default</span> <span class="classifier-delimiter">:</span> <span class="classifier">0</span></dt>
<dd><blockquote class="first">
<div>Number of threads used to run inference.
By default inference runs with maximum number of available threads.</div></blockquote>
<dl class="last docutils">
<dt>proba: array-like, shape = (n_samples,)</dt>
<dd>Returns the predicted class of the sample.</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li><a href="index.html">home</a>|&nbsp;</li>
        <li><a href="search.html">search</a>|&nbsp;</li>
 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2018, cdu.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.8.2.
    </div>
  </body>
</html>