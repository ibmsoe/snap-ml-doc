
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>snap-ml-local API &#8212; Snap Machine Learning 1.0 documentation</title>
    <link rel="stylesheet" href="_static/nature.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <script type="text/javascript" src="_static/documentation_options.js"></script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" /> 
  </head><body>

<div style="background-color: white; text-align: left; padding: 10px 10px 15px 15px">
<a href="index.html"><h1 style="font-size: 3em;">Snap Machine Learning</h1></a>
</div>

    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li><a href="index.html">home</a>|&nbsp;</li>
        <li><a href="search.html">search</a>|&nbsp;</li>
 
      </ul>
    </div>

      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="snap-ml-local-api">
<span id="python-api-documentation"></span><h1>snap-ml-local API<a class="headerlink" href="#snap-ml-local-api" title="Permalink to this headline">¶</a></h1>
<dl class="class">
<dt id="pai4sk.LinearRegression">
<em class="property">class </em><code class="descclassname">pai4sk.</code><code class="descname">LinearRegression</code><span class="sig-paren">(</span><em>max_iter=1000</em>, <em>regularizer=1.0</em>, <em>device_ids=[]</em>, <em>verbose=False</em>, <em>use_gpu=False</em>, <em>dual=True</em>, <em>num_threads=1</em>, <em>penalty='l2'</em>, <em>tol=0.001</em>, <em>return_training_history=None</em>, <em>privacy=False</em>, <em>eta=0.3</em>, <em>batch_size=100</em>, <em>privacy_epsilon=10</em>, <em>grad_clip=1</em>, <em>fit_intercept=False</em>, <em>intercept_scaling=1.0</em><span class="sig-paren">)</span><a class="headerlink" href="#pai4sk.LinearRegression" title="Permalink to this definition">¶</a></dt>
<dd><p>Linear Regression</p>
<p>This class implements regularized linear regression using the IBM Snap ML solver.
It handles both dense and sparse matrix inputs. Use csr, csc or ndarray matrix format
for training and csr or ndarray format for prediction.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>default : 1000</em>) – Maximum number of iterations used by the solver to converge.</li>
<li><strong>regularizer</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>default : 1.0</em>) – Regularization strength. It must be a positive float.
Larger regularization values imply stronger regularization.</li>
<li><strong>use_gpu</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>default : False</em>) – Flag for indicating the hardware platform used for training. If True, the training
is performed using the GPU. If False, the training is performed using the CPU.</li>
<li><strong>device_ids</strong> (<em>array-like of int</em><em>, </em><em>default :</em><em> [</em><em>]</em>) – If use_gpu is True, it indicates the IDs of the GPUs used for training.
For single GPU training, set device_ids to the GPU ID to be used for training, e.g., [0].
For multi-GPU training, set device_ids to a list of GPU IDs to be used for training, e.g., [0, 1].</li>
<li><strong>dual</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>default : True</em>) – Dual or primal formulation.
Recommendation: if n_samples &gt; n_features use dual=True.</li>
<li><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>default : False</em>) – If True, it prints the training cost, one per iteration. Warning: this will increase the
training time. For performance evaluation, use verbose=False.</li>
<li><strong>num_threads</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>default : 1</em>) – The number of threads used for running the training. The value of this parameter
should be a multiple of 32 if the training is performed on GPU (use_gpu=True).</li>
<li><strong>penalty</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a><em>, </em><em>default : &quot;l2&quot;</em>) – The regularization / penalty type. Possible values are “l2” for L2 regularization (RidgeRegression)
or “l1” for L1 regularization (LassoRegression). L1 regularization is possible only for the primal
optimization problem (dual=False).</li>
<li><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>default : 0.001</em>) – The tolerance parameter. Training will finish when maximum change in model coefficients is less than tol.</li>
<li><strong>return_training_history</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a><em> or </em><em>None</em><em>, </em><em>default : None</em>) – How much information about the training should be collected and returned by the fit function. By
default no information is returned (None), but this parameter can be set to “summary”, to obtain
summary statistics at the end of training, or “full” to obtain a complete set of statistics
for the entire training procedure. Note, enabling either option will result in slower training.</li>
<li><strong>privacy</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>default : False</em>) – Train the model using a differentially private algorithm.</li>
<li><strong>eta</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>default : 0.3</em>) – Learning rate for the differentially private training algorithm.</li>
<li><strong>batch_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>default : 100</em>) – Mini-batch size for the differentially private training algorithm.</li>
<li><strong>privacy_epsilon</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>default : 10.0</em>) – Target privacy gaurantee. Learned model will be (privacy_epsilon, 0.01)-private.</li>
<li><strong>grad_clip</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>default: 1.0</em>) – Gradient clipping parameter for the differentially private training algorithm</li>
<li><strong>fit_intercept</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>default : False</em>) – Add bias term – note, may affect speed of convergence, especially for sparse datasets.</li>
<li><strong>intercept_scaling</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>default : 1.0</em>) – Scaling of bias term. The inclusion of a bias term is implemented by appending an additional feature to the
dataset. This feature has a constant value, that can be set using this parameter.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Variables:</th><td class="field-body"><ul class="first last simple">
<li><strong>coef</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_features</em><em>,</em><em>)</em>) – Coefficients of the features in the trained model.</li>
<li><strong>support</strong> (<em>array-like</em>) – Indices of the features that lie in the support ond contribute to the decision. (only available for L1)</li>
<li><strong>model_sparsity</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a>) – fraction of non-zeros in the model parameters. (only available for L1)</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="pai4sk.LinearRegression.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X_train</em>, <em>y_train</em><span class="sig-paren">)</span><a class="headerlink" href="#pai4sk.LinearRegression.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the model according to the given train dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X_train</strong> (<em>sparse matrix</em><em> (</em><em>e.g.</em><em>, </em><em>scipy.sparse.csr_matrix</em><em>, </em><em>scipy.sparse.csc_matrix</em><em>)</em>) – Train dataset</li>
<li><strong>y_train</strong> (<em>array-like</em><em>, </em><em>shape =</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) – The target vector corresponding to X_train.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>self</strong></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)">object</a></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pai4sk.LinearRegression.get_params">
<code class="descname">get_params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pai4sk.LinearRegression.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the values of the model parameters.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><strong>params</strong></td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.7)">dict</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pai4sk.LinearRegression.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>X</em>, <em>num_threads=0</em><span class="sig-paren">)</span><a class="headerlink" href="#pai4sk.LinearRegression.predict" title="Permalink to this definition">¶</a></dt>
<dd><blockquote>
<div><p>Class predictions</p>
<p>The returned class estimates.</p>
<dl class="docutils">
<dt>X <span class="classifier-delimiter">:</span> <span class="classifier">sparse matrix (csr_matrix) or dense matrix (ndarray)</span></dt>
<dd>Dataset used for predicting class estimates.</dd>
</dl>
</div></blockquote>
<dl class="docutils">
<dt>num_threads <span class="classifier-delimiter">:</span> <span class="classifier">int, default</span> <span class="classifier-delimiter">:</span> <span class="classifier">0</span></dt>
<dd><blockquote class="first">
<div>Number of threads used to run inference.
By default inference runs with maximum number of available threads.</div></blockquote>
<dl class="last docutils">
<dt>proba: array-like, shape = (n_samples,)</dt>
<dd>Returns the predicted class of the sample.</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="pai4sk.LogisticRegression">
<em class="property">class </em><code class="descclassname">pai4sk.</code><code class="descname">LogisticRegression</code><span class="sig-paren">(</span><em>max_iter=1000</em>, <em>regularizer=1.0</em>, <em>device_ids=[]</em>, <em>verbose=False</em>, <em>use_gpu=False</em>, <em>class_weight=None</em>, <em>dual=True</em>, <em>num_threads=1</em>, <em>penalty='l2'</em>, <em>tol=0.001</em>, <em>return_training_history=None</em>, <em>privacy=False</em>, <em>eta=0.3</em>, <em>batch_size=100</em>, <em>privacy_epsilon=10</em>, <em>grad_clip=1</em>, <em>fit_intercept=False</em>, <em>intercept_scaling=1.0</em><span class="sig-paren">)</span><a class="headerlink" href="#pai4sk.LogisticRegression" title="Permalink to this definition">¶</a></dt>
<dd><p>Logistic Regression classifier</p>
<p>This class implements regularized logistic regression using the IBM Snap ML solver.
It can be used for both binary and multi-class classification problems. For multi-class
classification it predicts only classes (no probabilities). It handles both dense and
sparse matrix inputs. Use csr, csc or ndarray matrix format for training and csr or
ndarray format for prediction. We recommend the user to first normalize the input values.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>default : 1000</em>) – Maximum number of iterations used by the solver to converge.</li>
<li><strong>regularizer</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>default : 1.0</em>) – Regularization strength. It must be a positive float.
Larger regularization values imply stronger regularization.</li>
<li><strong>use_gpu</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>default : False</em>) – Flag for indicating the hardware platform used for training. If True, the training
is performed using the GPU. If False, the training is performed using the CPU.</li>
<li><strong>device_ids</strong> (<em>array-like of int</em><em>, </em><em>default :</em><em> [</em><em>]</em>) – If use_gpu is True, it indicates the IDs of the GPUs used for training.
For single-GPU training, set device_ids to the GPU ID to be used for training, e.g., [0].
For multi-GPU training, set device_ids to a list of GPU IDs to be used for training, e.g., [0, 1].</li>
<li><strong>class_weight</strong> (<em>'balanced'</em><em> or </em><em>None</em><em>, </em><em>optional</em>) – If set to ‘None’, all classes will have weight 1.</li>
<li><strong>dual</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>default : True</em>) – Dual or primal formulation.
Recommendation: if n_samples &gt; n_features use dual=True.</li>
<li><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>default : False</em>) – If True, it prints the training cost, one per iteration. Warning: this will increase the
training time. For performance evaluation, use verbose=False.</li>
<li><strong>num_threads</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>default : 1</em>) – The number of threads used for running the training. The value of this parameter
should be a multiple of 32 if the training is performed on GPU (use_gpu=True).</li>
<li><strong>penalty</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a><em>, </em><em>default : &quot;l2&quot;</em>) – The regularization / penalty type. Possible values are “l2” for L2 regularization (LogisticRegression)
or “l1” for L1 regularization (SparseLogisticRegression). L1 regularization is possible only for the primal
optimization problem (dual=False).</li>
<li><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>default : 0.001</em>) – The tolerance parameter. Training will finish when maximum change in model coefficients is less than tol.</li>
<li><strong>return_training_history</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a><em> or </em><em>None</em><em>, </em><em>default : None</em>) – How much information about the training should be collected and returned by the fit function. By
default no information is returned (None), but this parameter can be set to “summary”, to obtain
summary statistics at the end of training, or “full” to obtain a complete set of statistics
for the entire training procedure. Note, enabling either option will result in slower training.</li>
<li><strong>privacy</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>default : False</em>) – Train the model using a differentially private algorithm.</li>
<li><strong>eta</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>default : 0.3</em>) – Learning rate for the differentially private training algorithm.</li>
<li><strong>batch_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>default : 100</em>) – Mini-batch size for the differentially private training algorithm.</li>
<li><strong>privacy_epsilon</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>default : 10.0</em>) – Target privacy gaurantee. Learned model will be (privacy_epsilon, 0.01)-private.</li>
<li><strong>grad_clip</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>default: 1.0</em>) – Gradient clipping parameter for the differentially private training algorithm</li>
<li><strong>fit_intercept</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>default : False</em>) – Add bias term – note, may affect speed of convergence, especially for sparse datasets.</li>
<li><strong>intercept_scaling</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>default : 1.0</em>) – Scaling of bias term. The inclusion of a bias term is implemented by appending an additional feature to the
dataset. This feature has a constant value, that can be set using this parameter.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Variables:</th><td class="field-body"><ul class="first last simple">
<li><strong>coef</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_features</em><em>,</em><em>) or </em><em>(</em><em>n_features</em><em>, </em><em>n_classes</em><em>) </em><em>for multi-class classification.</em>) – Coefficients of the features in the trained model.</li>
<li><strong>support</strong> (<em>array-like</em>) – Indices of the features that contribute to the decision. (only available for L1)</li>
<li><strong>model_sparsity</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a>) – fraction of non-zeros in the model parameters. (only available for L1)</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="pai4sk.LogisticRegression.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X_train</em>, <em>y_train</em><span class="sig-paren">)</span><a class="headerlink" href="#pai4sk.LogisticRegression.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the model according to the given train data.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X_train</strong> (<em>sparse matrix</em><em> (</em><em>csr_matrix</em><em>, </em><em>csc_matrix</em><em>) or </em><em>dense matrix</em><em> (</em><em>ndarray</em><em>)</em>) – Train dataset</li>
<li><strong>y_train</strong> (<em>array-like</em><em>, </em><em>shape =</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) – The target vector corresponding to X_train. For binary classification
the labels should be {-1, 1} or {0, 1}.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>self</strong></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)">object</a></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pai4sk.LogisticRegression.get_params">
<code class="descname">get_params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pai4sk.LogisticRegression.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the values of the model parameters.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><strong>params</strong></td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.7)">dict</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pai4sk.LogisticRegression.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>X</em>, <em>num_threads=0</em><span class="sig-paren">)</span><a class="headerlink" href="#pai4sk.LogisticRegression.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Class predictions</p>
<p>The returned class estimates.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>sparse matrix</em><em> (</em><em>csr_matrix</em><em>) or </em><em>dense matrix</em><em> (</em><em>ndarray</em><em>)</em>) – Dataset used for predicting class estimates.</li>
<li><strong>num_threads</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>default : 0</em>) – Number of threads used to run inference.
By default inference runs with maximum number of available threads.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>proba</strong> – Returns the predicted class of the sample.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">array-like, shape = (n_samples,)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pai4sk.LogisticRegression.predict_log_proba">
<code class="descname">predict_log_proba</code><span class="sig-paren">(</span><em>X</em>, <em>num_threads=0</em><span class="sig-paren">)</span><a class="headerlink" href="#pai4sk.LogisticRegression.predict_log_proba" title="Permalink to this definition">¶</a></dt>
<dd><p>Log of probability estimates</p>
<p>The returned log-probability estimates for the two classes.
Only for binary classification.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>sparse matrix</em><em> (</em><em>csr_matrix</em><em>) or </em><em>dense matrix</em><em> (</em><em>ndarray</em><em>)</em>) – Dataset used for predicting log-probability estimates.</li>
<li><strong>num_threads</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>default : 0</em>) – Number of threads used to run inference.
By default inference runs with maximum number of available threads.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>proba</strong> – Returns the log-probability of the sample for each of the two classes.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">array-like, shape = (n_samples, 2)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pai4sk.LogisticRegression.predict_proba">
<code class="descname">predict_proba</code><span class="sig-paren">(</span><em>X</em>, <em>num_threads=0</em><span class="sig-paren">)</span><a class="headerlink" href="#pai4sk.LogisticRegression.predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><p>Probability estimates</p>
<p>The returned probability estimates for the two classes.
Only for binary classification.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>sparse matrix</em><em> (</em><em>csr_matrix</em><em>) or </em><em>dense matrix</em><em> (</em><em>ndarray</em><em>)</em>) – Dataset used for predicting probability estimates.</li>
<li><strong>num_threads</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>default : 0</em>) – Number of threads used to run inference.
By default inference runs with maximum number of available threads.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>proba</strong> – Returns the probability of the sample of each of the two classes.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">array-like, shape = (n_samples, 2)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="pai4sk.SupportVectorMachine">
<em class="property">class </em><code class="descclassname">pai4sk.</code><code class="descname">SupportVectorMachine</code><span class="sig-paren">(</span><em>max_iter=1000</em>, <em>regularizer=1.0</em>, <em>device_ids=[]</em>, <em>verbose=False</em>, <em>use_gpu=False</em>, <em>class_weight=None</em>, <em>num_threads=1</em>, <em>tol=0.001</em>, <em>return_training_history=None</em>, <em>fit_intercept=False</em>, <em>intercept_scaling=1.0</em><span class="sig-paren">)</span><a class="headerlink" href="#pai4sk.SupportVectorMachine" title="Permalink to this definition">¶</a></dt>
<dd><p>Support Vector Machine classifier</p>
<p>This class implements regularized support vector machine using the IBM Snap ML solver.
It can be used for both binary and multi-class classification problems. For multi-class
classification it predicts classes or the decision function for each class in the model.
It handles both dense and sparse matrix inputs. Use csr or ndarray matrix format
for both training and prediction. The training uses the dual formulation. We recommend
the user to normalize the input values.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>default : 1000</em>) – Maximum number of iterations used by the solver to converge.</li>
<li><strong>regularizer</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>default : 1.0</em>) – Regularization strength. It must be a positive float.
Larger regularization values imply stronger regularization.</li>
<li><strong>use_gpu</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>default : False</em>) – Flag for indicating the hardware platform used for training. If True, the training
is performed using the GPU. If False, the training is performed using the CPU.</li>
<li><strong>device_ids</strong> (<em>array-like of int</em><em>, </em><em>default :</em><em> [</em><em>]</em>) – If use_gpu is True, it indicates the IDs of the GPUs used for training.
For single GPU training, set device_ids to the GPU ID to be used for training,
e.g., [0]. For multi-GPU training, set device_ids to a list of GPU IDs to be used
for training, e.g., [0, 1].</li>
<li><strong>class_weight</strong> (<em>'balanced'</em><em> or </em><em>None</em><em>, </em><em>optional</em>) – If set to ‘None’, all classes will have weight 1.</li>
<li><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>default : False</em>) – If True, it prints the training cost, one per iteration. Warning: this will increase
the training time. For performance evaluation, use verbose=False.</li>
<li><strong>num_threads</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>default : 1</em>) – The number of threads used for running the training. The value of this parameter
should be a multiple of 32 if the training is performed on GPU (use_gpu=True).</li>
<li><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>default : 0.001</em>) – The tolerance parameter. Training will finish when maximum change in model coefficients is less than tol.</li>
<li><strong>return_training_history</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a><em> or </em><em>None</em><em>, </em><em>default : None</em>) – How much information about the training should be collected and returned by the fit function. By
default no information is returned (None), but this parameter can be set to “summary”, to obtain
summary statistics at the end of training, or “full” to obtain a complete set of statistics
for the entire training procedure. Note, enabling either option will result in slower training.</li>
<li><strong>fit_intercept</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>default : False</em>) – Add bias term – note, may affect speed of convergence, especially for sparse datasets.</li>
<li><strong>intercept_scaling</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>default : 1.0</em>) – Scaling of bias term. The inclusion of a bias term is implemented by appending an additional feature to the
dataset. This feature has a constant value, that can be set using this parameter.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Variables:</th><td class="field-body"><ul class="first last simple">
<li><strong>coef</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_features</em><em>,</em><em>) or </em><em>(</em><em>n_features</em><em>, </em><em>n_classes</em><em>) </em><em>for multi-class classification.</em>) – Coefficients of the features in the trained model.</li>
<li><strong>support</strong> (<em>array-like</em><em>,  </em><em>shape</em><em> (</em><em>n_SV</em><em>)</em>) – indices of the support vectors.</li>
<li><strong>n_support</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – Number of support vectors.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="pai4sk.SupportVectorMachine.decision_function">
<code class="descname">decision_function</code><span class="sig-paren">(</span><em>X</em>, <em>num_threads=0</em><span class="sig-paren">)</span><a class="headerlink" href="#pai4sk.SupportVectorMachine.decision_function" title="Permalink to this definition">¶</a></dt>
<dd><p>Predicts confidence scores.</p>
<p>The confidence score of a sample is the signed distance of that sample to the decision boundary.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>sparse matrix</em><em> (</em><em>csr_matrix</em><em>) or </em><em>dense matrix</em><em> (</em><em>ndarray</em><em>)</em>) – Dataset used for predicting distances to the decision boundary.</li>
<li><strong>num_threads</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>default : 0</em>) – Number of threads used to run inference.
By default inference runs with maximum number of available threads.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>proba</strong> – Returns the distance to the decision boundary of the samples in X.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">array-like, shape = (n_samples,) or (n_sample, n_classes)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pai4sk.SupportVectorMachine.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X_train</em>, <em>y_train</em><span class="sig-paren">)</span><a class="headerlink" href="#pai4sk.SupportVectorMachine.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the model according to the given train dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X_train</strong> (<em>sparse matrix</em><em> (</em><em>csr_matrix</em><em>) or </em><em>dense matrix</em><em> (</em><em>ndarray</em><em>)</em>) – Train dataset</li>
<li><strong>y_train</strong> (<em>array-like</em><em>, </em><em>shape =</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) – The target vector corresponding to X_train. For binary classification
the labels should be {-1, 1} or {0, 1}.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>self</strong></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)">object</a></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pai4sk.SupportVectorMachine.get_params">
<code class="descname">get_params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pai4sk.SupportVectorMachine.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the values of the model parameters.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><strong>params</strong></td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.7)">dict</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pai4sk.SupportVectorMachine.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>X</em>, <em>num_threads=0</em><span class="sig-paren">)</span><a class="headerlink" href="#pai4sk.SupportVectorMachine.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Class predictions</p>
<p>The returned class estimates.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>sparse matrix</em><em> (</em><em>csr_matrix</em><em>) or </em><em>dense matrix</em><em> (</em><em>ndarray</em><em>)</em>) – Dataset used for predicting class estimates.</li>
<li><strong>num_threads</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>default : 0</em>) – Number of threads used to run inference.
By default inference runs with maximum number of available threads.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>proba</strong> – Returns the predicted class of the samples in X.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">array-like, shape = (n_samples,)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li><a href="index.html">home</a>|&nbsp;</li>
        <li><a href="search.html">search</a>|&nbsp;</li>
 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2018, cdu.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.7.4.
    </div>
  </body>
</html>