
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>snap-ml API &#8212; Snap Machine Learning 1.0 documentation</title>
    <link rel="stylesheet" href="_static/nature.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" /> 
  </head><body>

<div style="background-color: white; text-align: left; padding: 10px 10px 15px 15px">
<a href="index.html"><h1 style="font-size: 3em;">Snap Machine Learning</h1></a>
</div>

    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li><a href="index.html">home</a>|&nbsp;</li>
        <li><a href="search.html">search</a>|&nbsp;</li>
 
      </ul>
    </div>

      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="snap-ml-api">
<span id="python-api-documentation"></span><h1>snap-ml API<a class="headerlink" href="#snap-ml-api" title="Permalink to this headline">¶</a></h1>
<dl class="class">
<dt id="pai4sk.LinearRegression">
<em class="property">class </em><code class="descclassname">pai4sk.</code><code class="descname">LinearRegression</code><span class="sig-paren">(</span><em>max_iter=1000</em>, <em>regularizer=1.0</em>, <em>device_ids=[]</em>, <em>verbose=False</em>, <em>use_gpu=False</em>, <em>dual=True</em>, <em>num_threads=1</em>, <em>penalty='l2'</em>, <em>tol=0.001</em>, <em>return_training_history=None</em>, <em>privacy=False</em>, <em>eta=0.3</em>, <em>batch_size=100</em>, <em>privacy_epsilon=10</em>, <em>grad_clip=1</em>, <em>fit_intercept=False</em>, <em>intercept_scaling=1.0</em><span class="sig-paren">)</span><a class="headerlink" href="#pai4sk.LinearRegression" title="Permalink to this definition">¶</a></dt>
<dd><p>Linear Regression</p>
<p>This class implements regularized linear regression using the IBM Snap ML solver.
It supports both local and distributed(MPI) methods of the snap ML solver. It
handles both dense and sparse matrix inputs. Use csr, csc, ndarray, deviceNDArray
or SnapML data partition format for training and csr, ndarray or
SnapML data partition format for prediction. DeviceNDArray input data format is
currently not supported for training with MPI implementation.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>default : 1000</em>) – Maximum number of iterations used by the solver to converge.</li>
<li><strong>regularizer</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>default : 1.0</em>) – Regularization strength. It must be a positive float.
Larger regularization values imply stronger regularization.</li>
<li><strong>use_gpu</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>default : False</em>) – Flag for indicating the hardware platform used for training. If True, the training
is performed using the GPU. If False, the training is performed using the CPU.</li>
<li><strong>device_ids</strong> (<em>array-like of int</em><em>, </em><em>default :</em><em> [</em><em>]</em>) – If use_gpu is True, it indicates the IDs of the GPUs used for training.
For single GPU training, set device_ids to the GPU ID to be used for training, e.g., [0].
For multi-GPU training, set device_ids to a list of GPU IDs to be used for training, e.g., [0, 1].</li>
<li><strong>dual</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>default : True</em>) – Dual or primal formulation.
Recommendation: if n_samples &gt; n_features use dual=True.</li>
<li><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>default : False</em>) – If True, it prints the training cost, one per iteration. Warning: this will increase the
training time. For performance evaluation, use verbose=False.</li>
<li><strong>num_threads</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>default : 1</em>) – The number of threads used for running the training. The value of this parameter
should be a multiple of 32 if the training is performed on GPU (use_gpu=True).</li>
<li><strong>penalty</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a><em>, </em><em>default : &quot;l2&quot;</em>) – The regularization / penalty type. Possible values are “l2” for L2 regularization (RidgeRegression)
or “l1” for L1 regularization (LassoRegression). L1 regularization is possible only for the primal
optimization problem (dual=False).</li>
<li><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>default : 0.001</em>) – The tolerance parameter. Training will finish when maximum change in model coefficients is less than tol.</li>
<li><strong>return_training_history</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.7)"><em>None</em></a><em>, </em><em>default : None</em>) – How much information about the training should be collected and returned by the fit function. By
default no information is returned (None), but this parameter can be set to “summary”, to obtain
summary statistics at the end of training, or “full” to obtain a complete set of statistics
for the entire training procedure. Note, enabling either option will result in slower training.
return_training_history is not supported for DeviceNDArray input format.</li>
<li><strong>privacy</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>default : False</em>) – Train the model using a differentially private algorithm.
Currently not supported for MPI implementation.</li>
<li><strong>eta</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>default : 0.3</em>) – Learning rate for the differentially private training algorithm.
Currently not supported for MPI implementation.</li>
<li><strong>batch_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>default : 100</em>) – Mini-batch size for the differentially private training algorithm.
Currently not supported for MPI implementation.</li>
<li><strong>privacy_epsilon</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>default : 10.0</em>) – Target privacy gaurantee. Learned model will be (privacy_epsilon, 0.01)-private.
Currently not supported for MPI implementation.</li>
<li><strong>grad_clip</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>default: 1.0</em>) – Gradient clipping parameter for the differentially private training algorithm.
Currently not supported for MPI implementation.</li>
<li><strong>fit_intercept</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>default : False</em>) – Add bias term – note, may affect speed of convergence, especially for sparse datasets.</li>
<li><strong>intercept_scaling</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>default : 1.0</em>) – Scaling of bias term. The inclusion of a bias term is implemented by appending an additional feature to the
dataset. This feature has a constant value, that can be set using this parameter.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Variables:</th><td class="field-body"><ul class="first last simple">
<li><strong>coef</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_features</em><em>,</em><em>)</em>) – Coefficients of the features in the trained model.</li>
<li><strong>support</strong> (<em>array-like</em>) – Indices of the features that lie in the support ond contribute to the decision. (only available for L1).
Currently not supported for MPI implementation.</li>
<li><strong>model_sparsity</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a>) – fraction of non-zeros in the model parameters. (only available for L1).
Currently not supported for MPI implementation.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="pai4sk.LinearRegression.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X_train</em>, <em>y_train=None</em><span class="sig-paren">)</span><a class="headerlink" href="#pai4sk.LinearRegression.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the model according to the given train dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X_train</strong> (<em>Train dataset. Supports the following input data-types :</em>) – <ol class="arabic">
<li>Sparse matrix (csr_matrix, csc_matrix) or dense matrix (ndarray)</li>
<li>DeviceNDArray. Not supported for MPI execution.</li>
<li>SnapML data partition of type DensePartition, SparsePartition or ConstantValueSparsePartition</li>
</ol>
</li>
<li><strong>y_train</strong> (<em>The target corresponding to X_train.</em>) – If X_train is sparse matrix or dense matrix, y_train should be array-like of shape = (n_samples,)
In case of deviceNDArray, y_train should be array-like of shape = (n_samples, 1)
If X_train is SnapML data partition type, then y_train is not required (i.e. None).</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>self</strong></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)">object</a></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pai4sk.LinearRegression.get_params">
<code class="descname">get_params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pai4sk.LinearRegression.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the values of the model parameters.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><strong>params</strong></td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.7)">dict</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pai4sk.LinearRegression.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>X</em>, <em>num_threads=0</em><span class="sig-paren">)</span><a class="headerlink" href="#pai4sk.LinearRegression.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Class predictions</p>
<p>The returned class estimates.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>Dataset used for predicting estimates. Supports the following input data-types :</em>) – <ol class="arabic">
<li>Sparse matrix (csr_matrix, csc_matrix) or dense matrix (ndarray)</li>
<li>SnapML data partition of type DensePartition, SparsePartition or ConstantValueSparsePartition</li>
</ol>
</li>
<li><strong>num_threads</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>default : 0</em>) – Number of threads used to run inference.
By default inference runs with maximum number of available threads.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>proba</strong> – Returns the predicted estimate of the sample.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">array-like, shape = (n_samples,)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="pai4sk.LogisticRegression">
<em class="property">class </em><code class="descclassname">pai4sk.</code><code class="descname">LogisticRegression</code><span class="sig-paren">(</span><em>max_iter=1000</em>, <em>regularizer=1.0</em>, <em>device_ids=[]</em>, <em>verbose=False</em>, <em>use_gpu=False</em>, <em>class_weight=None</em>, <em>dual=True</em>, <em>num_threads=1</em>, <em>penalty='l2'</em>, <em>tol=0.001</em>, <em>return_training_history=None</em>, <em>privacy=False</em>, <em>eta=0.3</em>, <em>batch_size=100</em>, <em>privacy_epsilon=10</em>, <em>grad_clip=1</em>, <em>fit_intercept=False</em>, <em>intercept_scaling=1.0</em><span class="sig-paren">)</span><a class="headerlink" href="#pai4sk.LogisticRegression" title="Permalink to this definition">¶</a></dt>
<dd><p>Logistic Regression classifier</p>
<p>This class implements regularized logistic regression using the IBM Snap ML solver.
It supports both local and distributed(MPI) methods of the Snap ML solver. It
can be used for both binary and multi-class classification problems. For multi-class
classification it predicts only classes (no probabilities). It handles both dense and
sparse matrix inputs. Use csr, csc, ndarray, deviceNDArray or SnapML data partition format
for training and csr, ndarray or SnapML data partition format for prediction.
DeviceNDArray input data format is currently not supported for training with MPI implementation.
We recommend the user to first normalize the input values.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>default : 1000</em>) – Maximum number of iterations used by the solver to converge.</li>
<li><strong>regularizer</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>default : 1.0</em>) – Regularization strength. It must be a positive float.
Larger regularization values imply stronger regularization.</li>
<li><strong>use_gpu</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>default : False</em>) – Flag for indicating the hardware platform used for training. If True, the training
is performed using the GPU. If False, the training is performed using the CPU.</li>
<li><strong>device_ids</strong> (<em>array-like of int</em><em>, </em><em>default :</em><em> [</em><em>]</em>) – If use_gpu is True, it indicates the IDs of the GPUs used for training.
For single-GPU training, set device_ids to the GPU ID to be used for training, e.g., [0].
For multi-GPU training, set device_ids to a list of GPU IDs to be used for training, e.g., [0, 1].</li>
<li><strong>class_weight</strong> (<em>'balanced'</em><em> or </em><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.7)"><em>None</em></a><em>, </em><em>optional</em>) – If set to ‘None’, all classes will have weight 1.</li>
<li><strong>dual</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>default : True</em>) – Dual or primal formulation.
Recommendation: if n_samples &gt; n_features use dual=True.</li>
<li><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>default : False</em>) – If True, it prints the training cost, one per iteration. Warning: this will increase the
training time. For performance evaluation, use verbose=False.</li>
<li><strong>num_threads</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>default : 1</em>) – The number of threads used for running the training. The value of this parameter
should be a multiple of 32 if the training is performed on GPU (use_gpu=True).</li>
<li><strong>penalty</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a><em>, </em><em>default : &quot;l2&quot;</em>) – The regularization / penalty type. Possible values are “l2” for L2 regularization (LogisticRegression)
or “l1” for L1 regularization (SparseLogisticRegression). L1 regularization is possible only for the primal
optimization problem (dual=False).</li>
<li><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>default : 0.001</em>) – The tolerance parameter. Training will finish when maximum change in model coefficients is less than tol.</li>
<li><strong>return_training_history</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.7)"><em>None</em></a><em>, </em><em>default : None</em>) – How much information about the training should be collected and returned by the fit function. By
default no information is returned (None), but this parameter can be set to “summary”, to obtain
summary statistics at the end of training, or “full” to obtain a complete set of statistics
for the entire training procedure. Note, enabling either option will result in slower training.
return_training_history is not supported for DeviceNDArray input format.</li>
<li><strong>privacy</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>default : False</em>) – Train the model using a differentially private algorithm.
Currently not supported for MPI implementation.</li>
<li><strong>eta</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>default : 0.3</em>) – Learning rate for the differentially private training algorithm.
Currently not supported for MPI implementation.</li>
<li><strong>batch_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>default : 100</em>) – Mini-batch size for the differentially private training algorithm.
Currently not supported for MPI implementation.</li>
<li><strong>privacy_epsilon</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>default : 10.0</em>) – Target privacy gaurantee. Learned model will be (privacy_epsilon, 0.01)-private.
Currently not supported for MPI implementation.</li>
<li><strong>grad_clip</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>default: 1.0</em>) – Gradient clipping parameter for the differentially private training algorithm.
Currently not supported for MPI implementation.</li>
<li><strong>fit_intercept</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>default : False</em>) – Add bias term – note, may affect speed of convergence, especially for sparse datasets.</li>
<li><strong>intercept_scaling</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>default : 1.0</em>) – Scaling of bias term. The inclusion of a bias term is implemented by appending an additional feature to the
dataset. This feature has a constant value, that can be set using this parameter.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Variables:</th><td class="field-body"><ul class="first last simple">
<li><strong>coef</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_features</em><em>, </em><em>1</em><em>) </em><em>for binary classification or</em>) – (n_features, n_classes) for multi-class classification.
Coefficients of the features in the trained model.</li>
<li><strong>support</strong> (<em>array-like</em>) – Indices of the features that contribute to the decision. (only available for L1)
Currently not supported for MPI implementation.</li>
<li><strong>model_sparsity</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a>) – fraction of non-zeros in the model parameters. (only available for L1)
Currently not supported for MPI implementation.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="pai4sk.LogisticRegression.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X_train</em>, <em>y_train=None</em><span class="sig-paren">)</span><a class="headerlink" href="#pai4sk.LogisticRegression.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the model according to the given train data.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X_train</strong> (<em>Train dataset. Supports the following input data-types :</em>) – <ol class="arabic">
<li>Sparse matrix (csr_matrix, csc_matrix) or dense matrix (ndarray)</li>
<li>DeviceNDArray. Not supported for MPI execution.</li>
<li>SnapML data partition of type DensePartition, SparsePartition or ConstantValueSparsePartition</li>
</ol>
</li>
<li><strong>y_train</strong> (<em>The target corresponding to X_train.</em>) – If X_train is sparse matrix or dense matrix, y_train should be array-like of shape = (n_samples,)
In case of deviceNDArray, y_train should be array-like of shape = (n_samples, 1)
For binary classification the labels should be {-1, 1} or {0, 1}.
If X_train is SnapML data partition type, then y_train is not required (i.e. None).</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>self</strong></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)">object</a></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pai4sk.LogisticRegression.get_params">
<code class="descname">get_params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pai4sk.LogisticRegression.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the values of the model parameters.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><strong>params</strong></td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.7)">dict</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pai4sk.LogisticRegression.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>X</em>, <em>num_threads=0</em><span class="sig-paren">)</span><a class="headerlink" href="#pai4sk.LogisticRegression.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Class predictions</p>
<p>The returned class estimates.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>Dataset used for predicting class estimates. Supports the following input data-types :</em>) – <ol class="arabic">
<li>Sparse matrix (csr_matrix, csc_matrix) or dense matrix (ndarray)</li>
<li>SnapML data partition of type DensePartition, SparsePartition or ConstantValueSparsePartition</li>
</ol>
</li>
<li><strong>num_threads</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>default : 0</em>) – Number of threads used to run inference.
By default inference runs with maximum number of available threads.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>proba</strong> – Returns the predicted class of the sample.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">array-like, shape = (n_samples,)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pai4sk.LogisticRegression.predict_log_proba">
<code class="descname">predict_log_proba</code><span class="sig-paren">(</span><em>X</em>, <em>num_threads=0</em><span class="sig-paren">)</span><a class="headerlink" href="#pai4sk.LogisticRegression.predict_log_proba" title="Permalink to this definition">¶</a></dt>
<dd><p>Log of probability estimates</p>
<p>The returned log-probability estimates for the two classes.
Only for binary classification.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>Dataset used for predicting log-probability estimates. Supports the following input data-types :</em>) – <ol class="arabic">
<li>Sparse matrix (csr_matrix, csc_matrix) or dense matrix (ndarray)</li>
<li>SnapML data partition of type DensePartition, SparsePartition or ConstantValueSparsePartition</li>
</ol>
</li>
<li><strong>num_threads</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>default : 0</em>) – Number of threads used to run inference.
By default inference runs with maximum number of available threads.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><p><strong>proba</strong> –      array-like of shape = (n_samples, 2)
Returns the log-probability of the sample to be a positive example for MPI :</p>
<blockquote>
<div><p>array-like of shape = (n_samples,)</p>
</div></blockquote>
</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">Returns the log-probability of the sample of each of the two classes for local implementation :</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pai4sk.LogisticRegression.predict_proba">
<code class="descname">predict_proba</code><span class="sig-paren">(</span><em>X</em>, <em>num_threads=0</em><span class="sig-paren">)</span><a class="headerlink" href="#pai4sk.LogisticRegression.predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><p>Probability estimates</p>
<p>The returned probability estimates for the two classes.
Only for binary classification.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>Dataset used for predicting probability estimates. Supports the following input data-types :</em>) – <ol class="arabic">
<li>Sparse matrix (csr_matrix, csc_matrix) or dense matrix (ndarray)</li>
<li>SnapML data partition of type DensePartition, SparsePartition or ConstantValueSparsePartition</li>
</ol>
</li>
<li><strong>num_threads</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>default : 0</em>) – Number of threads used to run inference.
By default inference runs with maximum number of available threads.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><p><strong>proba</strong> –      array-like of shape = (n_samples, 2)
Returns the probability of the sample to be a positive example for MPI :</p>
<blockquote>
<div><p>array-like of shape = (n_samples,)</p>
</div></blockquote>
</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">Returns the probability of the sample of each of the two classes for local implementation :</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="pai4sk.SupportVectorMachine">
<em class="property">class </em><code class="descclassname">pai4sk.</code><code class="descname">SupportVectorMachine</code><span class="sig-paren">(</span><em>max_iter=1000</em>, <em>regularizer=1.0</em>, <em>device_ids=[]</em>, <em>verbose=False</em>, <em>use_gpu=False</em>, <em>class_weight=None</em>, <em>num_threads=1</em>, <em>tol=0.001</em>, <em>return_training_history=None</em>, <em>fit_intercept=False</em>, <em>intercept_scaling=1.0</em><span class="sig-paren">)</span><a class="headerlink" href="#pai4sk.SupportVectorMachine" title="Permalink to this definition">¶</a></dt>
<dd><p>Support Vector Machine classifier</p>
<p>This class implements regularized support vector machine using the IBM Snap ML solver.
It supports both local and distributed(MPI) methods of the Snap ML solver. It
can be used for both binary and multi-class classification problems. For multi-class
classification it predicts classes or the decision function for each class in the model.
It handles both dense and sparse matrix inputs. Use csr, ndarray, deviceNDArray or
SnapML data partition format for both training and prediction. DeviceNDArray input
data format is currently not supported for training with MPI implementation.
The training uses the dual formulation. We recommend the user to normalize the input values.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>max_iter</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>default : 1000</em>) – Maximum number of iterations used by the solver to converge.</li>
<li><strong>regularizer</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>default : 1.0</em>) – Regularization strength. It must be a positive float.
Larger regularization values imply stronger regularization.</li>
<li><strong>use_gpu</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>default : False</em>) – Flag for indicating the hardware platform used for training. If True, the training
is performed using the GPU. If False, the training is performed using the CPU.</li>
<li><strong>device_ids</strong> (<em>array-like of int</em><em>, </em><em>default :</em><em> [</em><em>]</em>) – If use_gpu is True, it indicates the IDs of the GPUs used for training.
For single GPU training, set device_ids to the GPU ID to be used for training,
e.g., [0]. For multi-GPU training, set device_ids to a list of GPU IDs to be used
for training, e.g., [0, 1].</li>
<li><strong>class_weight</strong> (<em>'balanced'</em><em> or </em><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.7)"><em>None</em></a><em>, </em><em>optional</em>) – If set to ‘None’, all classes will have weight 1.</li>
<li><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>default : False</em>) – If True, it prints the training cost, one per iteration. Warning: this will increase
the training time. For performance evaluation, use verbose=False.</li>
<li><strong>num_threads</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>default : 1</em>) – The number of threads used for running the training. The value of this parameter
should be a multiple of 32 if the training is performed on GPU (use_gpu=True).</li>
<li><strong>tol</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>default : 0.001</em>) – The tolerance parameter. Training will finish when maximum change in model coefficients is less than tol.</li>
<li><strong>return_training_history</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.7)"><em>None</em></a><em>, </em><em>default : None</em>) – How much information about the training should be collected and returned by the fit function. By
default no information is returned (None), but this parameter can be set to “summary”, to obtain
summary statistics at the end of training, or “full” to obtain a complete set of statistics
for the entire training procedure. Note, enabling either option will result in slower training.
return_training_history is not supported for DeviceNDArray input format.</li>
<li><strong>fit_intercept</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>default : False</em>) – Add bias term – note, may affect speed of convergence, especially for sparse datasets.</li>
<li><strong>intercept_scaling</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>default : 1.0</em>) – Scaling of bias term. The inclusion of a bias term is implemented by appending an additional feature to the
dataset. This feature has a constant value, that can be set using this parameter.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Variables:</th><td class="field-body"><ul class="first last simple">
<li><strong>coef</strong> (<em>array-like</em><em>, </em><em>shape</em><em> (</em><em>n_features</em><em>,</em><em>) </em><em>for binary classification or</em>) – (n_features, n_classes) for multi-class classification.
Coefficients of the features in the trained model.</li>
<li><strong>support</strong> (<em>array-like</em><em>,  </em><em>shape</em><em> (</em><em>n_SV</em><em>)</em>) – indices of the support vectors.
Currently not supported for MPI implementation.</li>
<li><strong>n_support</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – Number of support vectors.
Currently not supported for MPI implementation.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="pai4sk.SupportVectorMachine.decision_function">
<code class="descname">decision_function</code><span class="sig-paren">(</span><em>X</em>, <em>num_threads=0</em><span class="sig-paren">)</span><a class="headerlink" href="#pai4sk.SupportVectorMachine.decision_function" title="Permalink to this definition">¶</a></dt>
<dd><p>Predicts confidence scores.</p>
<p>The confidence score of a sample is the signed distance of that sample to the decision boundary.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>Dataset used for predicting distances to the decision boundary. Supports the following input data-types :</em>) – <ol class="arabic">
<li>Sparse matrix (csr_matrix, csc_matrix) or dense matrix (ndarray)</li>
<li>SnapML data partition of type DensePartition, SparsePartition or ConstantValueSparsePartition</li>
</ol>
</li>
<li><strong>num_threads</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>default : 0</em>) – Number of threads used to run inference.
By default inference runs with maximum number of available threads.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>proba</strong> – Returns the distance to the decision boundary of the samples in X.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">array-like, shape = (n_samples,) or (n_sample, n_classes)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pai4sk.SupportVectorMachine.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X_train</em>, <em>y_train=None</em><span class="sig-paren">)</span><a class="headerlink" href="#pai4sk.SupportVectorMachine.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the model according to the given train dataset.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X_train</strong> (<em>Train dataset. Supports the following input data-types :</em>) – <ol class="arabic">
<li>Sparse matrix (csr_matrix, csc_matrix) or dense matrix (ndarray)</li>
<li>DeviceNDArray. Not supported for MPI execution.</li>
<li>SnapML data partition of type DensePartition, SparsePartition or ConstantValueSparsePartition</li>
</ol>
</li>
<li><strong>y_train</strong> (<em>The target corresponding to X_train.</em>) – If X_train is sparse matrix or dense matrix, y_train should be array-like of shape = (n_samples,)
In case of deviceNDArray, y_train should be array-like of shape = (n_samples, 1)
For binary classification the labels should be {-1, 1} or {0, 1}.
If X_train is SnapML data partition type, then y_train is not required (i.e. None).</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>self</strong></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)">object</a></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pai4sk.SupportVectorMachine.get_params">
<code class="descname">get_params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pai4sk.SupportVectorMachine.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the values of the model parameters.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><strong>params</strong></td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.7)">dict</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pai4sk.SupportVectorMachine.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>X</em>, <em>num_threads=0</em><span class="sig-paren">)</span><a class="headerlink" href="#pai4sk.SupportVectorMachine.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Class predictions</p>
<p>The returned class estimates.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>Dataset used for predicting class estimates. Supports the following input data-types :</em>) – <ol class="arabic">
<li>Sparse matrix (csr_matrix) or dense matrix (ndarray)</li>
<li>SnapML data partition of type DensePartition, SparsePartition or ConstantValueSparsePartition</li>
</ol>
</li>
<li><strong>num_threads</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>default : 0</em>) – Number of threads used to run inference.
By default inference runs with maximum number of available threads.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>proba</strong> – Returns the predicted class of the samples in X.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">array-like, shape = (n_samples,)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="pai4sk.DecisionTreeClassifier">
<em class="property">class </em><code class="descclassname">pai4sk.</code><code class="descname">DecisionTreeClassifier</code><span class="sig-paren">(</span><em>criterion='gini'</em>, <em>splitter='best'</em>, <em>max_depth=None</em>, <em>min_samples_split=2</em>, <em>min_samples_leaf=1</em>, <em>max_features=None</em>, <em>random_state=None</em>, <em>max_leaf_nodes=None</em>, <em>presort=False</em>, <em>verbose=False</em>, <em>use_gpu=False</em>, <em>class_weight=None</em>, <em>num_threads=1</em><span class="sig-paren">)</span><a class="headerlink" href="#pai4sk.DecisionTreeClassifier" title="Permalink to this definition">¶</a></dt>
<dd><p>Decision Tree classifier</p>
<p>This class implements a traditional decision tree classifier using the IBM Snap ML library.
It can be used for binary classification problems. It handles both dense and
sparse matrix inputs. Use csr, csc or ndarray matrix format for training and csr or
ndarray format for prediction. [TODO] We recommend the user to first normalize the input values.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>criterion</strong> (<em>string</em><em>, </em><em>optional</em><em>, </em><em>default : &quot;gini&quot;</em>) – This function measures the quality of a split.
Possible values: “gini” and “entropy” for information gain.</li>
<li><strong>splitter</strong> (<em>string</em><em>, </em><em>optional</em><em>, </em><em>default : &quot;best&quot;</em>) – This parameter defines the strategy used to choose the split at each node. The currently
supported strategy is “best” to choose the best split. [TODO] Future strategy: “random” to
choose the best random split.</li>
<li><strong>max_depth</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.7)"><em>None</em></a><em>, </em><em>optional</em><em>, </em><em>default : None</em>) – The maximum depth of the tree. If None, then nodes are expanded until
all leaves are pure or until all leaves contain less than min_samples_split samples.</li>
<li><strong>min_samples_split</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>optional</em><em>, </em><em>default : 2</em>) – <p>The minimum number of samples required to split an internal node:
- If int, then consider <cite>min_samples_split</cite> as the minimum number.
- If float, then <cite>min_samples_split</cite> is a fraction and</p>
<blockquote>
<div><cite>ceil(min_samples_split * n_samples)</cite> are the minimum number of samples for each split.</div></blockquote>
</li>
<li><strong>min_samples_leaf</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>optional</em><em>, </em><em>default : 1</em>) – <p>The minimum number of samples required to be at a leaf node.
A split point at any depth will only be considered if it leaves at
least <code class="docutils literal notranslate"><span class="pre">min_samples_leaf</span></code> training samples in each of the left and
right branches.
- If int, then consider <cite>min_samples_leaf</cite> as the minimum number.
- If float, then <cite>min_samples_leaf</cite> is a fraction and</p>
<blockquote>
<div><cite>ceil(min_samples_leaf * n_samples)</cite> are the minimum number of samples for each node.</div></blockquote>
</li>
<li><strong>max_features</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>string</em><em> or </em><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.7)"><em>None</em></a><em>, </em><em>optional</em><em>, </em><em>default : None</em>) – <dl class="docutils">
<dt>The number of features to consider when looking for the best split:</dt>
<dd><ul class="first last">
<li>If int, then consider <cite>max_features</cite> features at each split.</li>
<li>If float, then <cite>max_features</cite> is a fraction and
<cite>int(max_features * n_features)</cite> features are considered at each
split.</li>
<li>If “auto”, then <cite>max_features=sqrt(n_features)</cite>.</li>
<li>If “sqrt”, then <cite>max_features=sqrt(n_features)</cite>.</li>
<li>If “log2”, then <cite>max_features=log2(n_features)</cite>.</li>
<li>If None, then <cite>max_features=n_features</cite>.</li>
</ul>
</dd>
</dl>
</li>
<li><strong>random_state</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, or </em><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.7)"><em>None</em></a><em>, </em><em>optional</em><em>, </em><em>default : None</em>) – If int, random_state is the seed used by the random number generator;
[TODO] Not yet supported: if RandomState instance, random_state is the random number generator;
If None, the random number generator is the RandomState instance used by <cite>np.random</cite>.</li>
<li><strong>max_leaf_nodes</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.7)"><em>None</em></a><em>, </em><em>optional</em><em>, </em><em>default : None</em>) – Grow a tree with <code class="docutils literal notranslate"><span class="pre">max_leaf_nodes</span></code> in best-first fashion.
Best nodes are defined as relative reduction in impurity.
If None then unlimited number of leaf nodes.</li>
<li><strong>min_impurity_decrease</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>optional</em><em>, </em><em>default : 0.</em>) – <p>[TODO] This parameter is not yet supported.
A node will be split if this split induces a decrease of the impurity
greater than or equal to this value.
The weighted impurity decrease equation is the following:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">N_t</span> <span class="o">/</span> <span class="n">N</span> <span class="o">*</span> <span class="p">(</span><span class="n">impurity</span> <span class="o">-</span> <span class="n">N_t_R</span> <span class="o">/</span> <span class="n">N_t</span> <span class="o">*</span> <span class="n">right_impurity</span>
                    <span class="o">-</span> <span class="n">N_t_L</span> <span class="o">/</span> <span class="n">N_t</span> <span class="o">*</span> <span class="n">left_impurity</span><span class="p">)</span>
</pre></div>
</div>
<p>where <code class="docutils literal notranslate"><span class="pre">N</span></code> is the total number of samples, <code class="docutils literal notranslate"><span class="pre">N_t</span></code> is the number of
samples at the current node, <code class="docutils literal notranslate"><span class="pre">N_t_L</span></code> is the number of samples in the
left child, and <code class="docutils literal notranslate"><span class="pre">N_t_R</span></code> is the number of samples in the right child.
<code class="docutils literal notranslate"><span class="pre">N</span></code>, <code class="docutils literal notranslate"><span class="pre">N_t</span></code>, <code class="docutils literal notranslate"><span class="pre">N_t_R</span></code> and <code class="docutils literal notranslate"><span class="pre">N_t_L</span></code> all refer to the weighted sum,
if <code class="docutils literal notranslate"><span class="pre">sample_weight</span></code> is passed.</p>
</li>
<li><strong>class_weight</strong> (<em>&quot;balanced&quot;</em><em> or </em><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.7)"><em>None</em></a><em>, </em><em>default : None</em>) – [TODO] Not yet supported. Weights associated with the available classes
If not given, all classes are supposed to have weight one.
The “balanced” mode uses the values of y to automatically adjust
weights inversely proportional to class frequencies in the input data
as <code class="docutils literal notranslate"><span class="pre">n_samples</span> <span class="pre">/</span> <span class="pre">(n_classes</span> <span class="pre">*</span> <span class="pre">np.bincount(y))</span></code></li>
<li><strong>presort</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em><em>, </em><em>default : False</em>) – [TODO] Not yet supported. Whether to presort the data to speed up the finding of best splits in
fitting. For the default settings of a decision tree on large
datasets, setting this to True may slow down the training process.
When using either a smaller dataset or a restricted depth, this may
speed up the training.</li>
<li><strong>use_gpu</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>default : False</em>) – Flag that indicates the hardware platform used for training. If True, the training
is performed using the GPU. If False, the training is performed using the CPU. Currently
only CPU training is supported. [TODO] Future solver: GPU.</li>
<li><strong>verbose</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>default : False</em>) – If True, it prints debugging information while training. Warning: this will increase the
training time. For performance evaluation, use verbose=False.</li>
<li><strong>num_threads</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>default : 1</em>) – The number of threads used for running the training. [TODO] The value of this parameter
should be a multiple of 32 if the training is performed on GPU (use_gpu=True) not yet supported.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Variables:</th><td class="field-body"><ul class="first last simple">
<li><strong>classes</strong> (<em>array of shape =</em><em> [</em><em>n_classes</em><em>]</em>) – The classes labels (single output problem)</li>
<li><strong>feature_importances</strong> (<em>array of shape =</em><em> [</em><em>n_features</em><em>]</em>) – [TODO] The feature importances. The higher, the more important the
feature. The importance of a feature is computed as the (normalized)
total reduction of the criterion brought by that feature.  It is also
known as the Gini importance <a href="#id3"><span class="problematic" id="id1">[4]_</span></a>.</li>
<li><strong>max_features</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>,</em>) – [TODO] The inferred value of max_features.</li>
<li><strong>n_classes</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – The number of classes (for single output problems)</li>
<li><strong>n_features</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – [TODO] The number of features when <code class="docutils literal notranslate"><span class="pre">fit</span></code> is performed.</li>
<li><strong>n_outputs</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – [TODO] The number of outputs when <code class="docutils literal notranslate"><span class="pre">fit</span></code> is performed.</li>
<li><strong>tree</strong> (<em>Tree object</em>) – [TODO] The underlying Tree object.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="pai4sk.DecisionTreeClassifier.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X_train</em>, <em>y_train</em><span class="sig-paren">)</span><a class="headerlink" href="#pai4sk.DecisionTreeClassifier.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the model according to the given train data.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X_train</strong> (<em>sparse matrix</em><em> (</em><em>csr_matrix</em><em>, </em><em>csc_matrix</em><em>) or </em><em>dense matrix</em><em> (</em><em>ndarray</em><em>)</em>) – Train dataset</li>
<li><strong>y_train</strong> (<em>array-like</em><em>, </em><em>shape =</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) – The target vector corresponding to X_train.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>self</strong></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)">object</a></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pai4sk.DecisionTreeClassifier.get_params">
<code class="descname">get_params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pai4sk.DecisionTreeClassifier.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the values of the model parameters.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><strong>params</strong></td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.7)">dict</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pai4sk.DecisionTreeClassifier.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>X</em>, <em>num_threads=0</em><span class="sig-paren">)</span><a class="headerlink" href="#pai4sk.DecisionTreeClassifier.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Class predictions</p>
<p>The returned class estimates.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>sparse matrix</em><em> (</em><em>csr_matrix</em><em>) or </em><em>dense matrix</em><em> (</em><em>ndarray</em><em>)</em>) – Dataset used for predicting class estimates.</li>
<li><strong>num_threads</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>default : 0</em>) – Number of threads used to run inference.
By default inference runs with maximum number of available threads.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>proba</strong> – Returns the predicted class of the sample.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">array-like, shape = (n_samples,)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pai4sk.DecisionTreeClassifier.predict_log_proba">
<code class="descname">predict_log_proba</code><span class="sig-paren">(</span><em>X</em>, <em>num_threads=0</em><span class="sig-paren">)</span><a class="headerlink" href="#pai4sk.DecisionTreeClassifier.predict_log_proba" title="Permalink to this definition">¶</a></dt>
<dd><p>Log of probability estimates</p>
<p>The returned log-probability estimates for the two classes.
Only for binary classification.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>sparse matrix</em><em> (</em><em>csr_matrix</em><em>) or </em><em>dense matrix</em><em> (</em><em>ndarray</em><em>)</em>) – Dataset used for predicting log-probability estimates.</li>
<li><strong>num_threads</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>default : 0</em>) – Number of threads used to run inference.
By default inference runs with maximum number of available threads.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>proba</strong> – Returns the log-probability of the sample for each of the two classes.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">array-like, shape = (n_samples, 2)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pai4sk.DecisionTreeClassifier.predict_proba">
<code class="descname">predict_proba</code><span class="sig-paren">(</span><em>X</em>, <em>num_threads=0</em><span class="sig-paren">)</span><a class="headerlink" href="#pai4sk.DecisionTreeClassifier.predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><p>Probability estimates</p>
<p>The returned probability estimates for the two classes.
Only for binary classification.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>sparse matrix</em><em> (</em><em>csr_matrix</em><em>) or </em><em>dense matrix</em><em> (</em><em>ndarray</em><em>)</em>) – Dataset used for predicting probability estimates.</li>
<li><strong>num_threads</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>default : 0</em>) – Number of threads used to run inferencei.
By default inference runs with maximum number of available threads.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>proba</strong> – Returns the probability of the sample of each of the two classes.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">array-like, shape = (n_samples, 2)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="pai4sk.RandomForestClassifier">
<em class="property">class </em><code class="descclassname">pai4sk.</code><code class="descname">RandomForestClassifier</code><span class="sig-paren">(</span><em>n_estimators=10</em>, <em>criterion='gini'</em>, <em>max_depth=None</em>, <em>min_samples_split=2</em>, <em>min_samples_leaf=1</em>, <em>max_features='auto'</em>, <em>max_leaf_nodes=None</em>, <em>bootstrap=True</em>, <em>n_jobs=None</em>, <em>random_state=None</em>, <em>verbose=False</em>, <em>class_weight=None</em>, <em>use_gpu=False</em><span class="sig-paren">)</span><a class="headerlink" href="#pai4sk.RandomForestClassifier" title="Permalink to this definition">¶</a></dt>
<dd><p>Random Forest Classifier</p>
<p>This class implements a random forest classifier using the IBM Snap ML library.
It can be used for binary classification problems. It handles both dense and
sparse matrix inputs. Use csr, csc or ndarray matrix format for training and csr or
ndarray format for prediction.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>n_estimators</strong> (<em>integer</em><em>, </em><em>optional</em><em>, </em><em>default : 10</em>) – This parameter defines the number of trees in forest.</li>
<li><strong>criterion</strong> (<em>string</em><em>, </em><em>optional</em><em>, </em><em>default : &quot;gini&quot;</em>) – This function measures the quality of a split. The currently supported criteria are “gini” and “entropy”.</li>
<li><strong>max_depth</strong> (<em>integer</em><em> or </em><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.7)"><em>None</em></a><em>, </em><em>optional</em><em>, </em><em>default : None</em>) – The maximum depth of the tree. If None, then nodes are expanded until
all leaves are pure or until all leaves contain less than min_samples_split samples.</li>
<li><strong>min_samples_split</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>optional</em><em>, </em><em>default : 2</em>) – <p>The minimum number of samples required to split an internal node:
- If int, then consider <cite>min_samples_split</cite> as the minimum number.
- If float, then <cite>min_samples_split</cite> is a fraction and</p>
<blockquote>
<div><cite>ceil(min_samples_split * n_samples)</cite> are the minimum number of samples for each split.</div></blockquote>
</li>
<li><strong>min_samples_leaf</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>optional</em><em>, </em><em>default : 1</em>) – <p>The minimum number of samples required to be at a leaf node.
A split point at any depth will only be considered if it leaves at
least <code class="docutils literal notranslate"><span class="pre">min_samples_leaf</span></code> training samples in each of the left and
right branches.
- If int, then consider <cite>min_samples_leaf</cite> as the minimum number.
- If float, then <cite>min_samples_leaf</cite> is a fraction and</p>
<blockquote>
<div><cite>ceil(min_samples_leaf * n_samples)</cite> are the minimum number of samples for each node.</div></blockquote>
</li>
<li><strong>max_features</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>string</em><em> or </em><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.7)"><em>None</em></a><em>, </em><em>optional</em><em>, </em><em>default : None</em>) – <dl class="docutils">
<dt>The number of features to consider when looking for the best split:</dt>
<dd><ul class="first last">
<li>If int, then consider <cite>max_features</cite> features at each split.</li>
<li>If float, then <cite>max_features</cite> is a fraction and
<cite>int(max_features * n_features)</cite> features are considered at each
split.</li>
<li>If “auto”, then <cite>max_features=sqrt(n_features)</cite>.</li>
<li>If “sqrt”, then <cite>max_features=sqrt(n_features)</cite>.</li>
<li>If “log2”, then <cite>max_features=log2(n_features)</cite>.</li>
<li>If None, then <cite>max_features=n_features</cite>.</li>
</ul>
</dd>
</dl>
</li>
<li><strong>max_leaf_nodes</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.7)"><em>None</em></a><em>, </em><em>optional</em><em>, </em><em>default : None</em>) – Grow a tree with <code class="docutils literal notranslate"><span class="pre">max_leaf_nodes</span></code> in best-first fashion.
Best nodes are defined as relative reduction in impurity.
If None then unlimited number of leaf nodes.</li>
<li><strong>bootstrap</strong> (<em>boolean</em><em>, </em><em>optional</em><em>, </em><em>default : True</em>) – This parameter determines whether bootstrap samples are used when building trees.</li>
<li><strong>n_jobs</strong> (<em>integer</em><em> or </em><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.7)"><em>None</em></a><em>, </em><em>optional</em><em>, </em><em>default : None</em>) – The number of jobs to run in parallel for both fit and predict.
None means 1 unless in a joblib.parallel_backend context. -1 means using all processors</li>
<li><strong>random_state</strong> (<em>integer</em><em>, or </em><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.7)"><em>None</em></a><em>, </em><em>optional</em><em>, </em><em>default : None</em>) – If integer, random_state is the seed used by the random number generator.
If None, the random number generator is the RandomState instance used by <cite>np.random</cite>.</li>
<li><strong>verbose</strong> (<em>boolean</em><em>, </em><em>default : False</em>) – If True, it prints debugging information while training.
Warning: this will increase the training time. For performance evaluation, use verbose=False.</li>
<li><strong>class_weight</strong> (<em>&quot;balanced&quot;</em><em> or </em><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.7)"><em>None</em></a><em>, </em><em>default : None</em>) – Weights associated with the available classes. If not given, all classes are supposed to have weight one.
The “balanced” mode uses the values of y to automatically adjust weights inversely proportional
to class frequencies in the input data as <code class="docutils literal notranslate"><span class="pre">n_samples</span> <span class="pre">/</span> <span class="pre">(n_classes</span> <span class="pre">*</span> <span class="pre">np.bincount(y))</span></code></li>
<li><strong>use_gpu</strong> (<em>boolean</em><em>, </em><em>default : False</em>) – Flag that indicates the hardware platform used for training. If True, the training
is performed using the GPU. If False, the training is performed using the CPU. Currently
only CPU training is supported. [TODO] Future solver: GPU.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Variables:</th><td class="field-body"><ul class="first last simple">
<li><strong>classes</strong> (<em>array of shape =</em><em> [</em><em>n_classes</em><em>]</em>) – The classes labels (single output problem)</li>
<li><strong>feature_importances</strong> (<em>array of shape =</em><em> [</em><em>n_features</em><em>]</em>) – The feature importances. The higher, the more important the
feature. The importance of a feature is computed as the (normalized)
total reduction of the criterion brought by that feature.  It is also
known as the Gini importance <a href="#id4"><span class="problematic" id="id2">[4]_</span></a>.</li>
<li><strong>max_features</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>,</em>) – The inferred value of max_features.</li>
<li><strong>n_classes</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – The number of classes (for single output problems)</li>
<li><strong>n_features</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – The number of features when <code class="docutils literal notranslate"><span class="pre">fit</span></code> is performed.</li>
<li><strong>n_outputs</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – The number of outputs when <code class="docutils literal notranslate"><span class="pre">fit</span></code> is performed.</li>
<li><strong>tree</strong> (<em>Tree object</em>) – [TODO] The underlying Tree object.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="pai4sk.RandomForestClassifier.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>X_train</em>, <em>y_train</em><span class="sig-paren">)</span><a class="headerlink" href="#pai4sk.RandomForestClassifier.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit the model according to the given train data.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X_train</strong> (<em>sparse matrix</em><em> (</em><em>csr_matrix</em><em>, </em><em>csc_matrix</em><em>) or </em><em>dense matrix</em><em> (</em><em>ndarray</em><em>)</em>) – Train dataset</li>
<li><strong>y_train</strong> (<em>array-like</em><em>, </em><em>shape =</em><em> (</em><em>n_samples</em><em>,</em><em>)</em>) – The target vector corresponding to X_train.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>self</strong></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last"><a class="reference external" href="https://docs.python.org/3/library/functions.html#object" title="(in Python v3.7)">object</a></p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pai4sk.RandomForestClassifier.get_params">
<code class="descname">get_params</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#pai4sk.RandomForestClassifier.get_params" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the values of the model parameters.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><strong>params</strong></td>
</tr>
<tr class="field-even field"><th class="field-name">Return type:</th><td class="field-body"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.7)">dict</a></td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pai4sk.RandomForestClassifier.predict">
<code class="descname">predict</code><span class="sig-paren">(</span><em>X</em>, <em>num_threads=0</em><span class="sig-paren">)</span><a class="headerlink" href="#pai4sk.RandomForestClassifier.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>Class predictions</p>
<p>The returned class estimates.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>sparse matrix</em><em> (</em><em>csr_matrix</em><em>) or </em><em>dense matrix</em><em> (</em><em>ndarray</em><em>)</em>) – Dataset used for predicting class estimates.</li>
<li><strong>num_threads</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>default : 0</em>) – Number of threads used to run inference.
By default inference runs with maximum number of available threads.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>proba</strong> – Returns the predicted class of the sample.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">array-like, shape = (n_samples,)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pai4sk.RandomForestClassifier.predict_log_proba">
<code class="descname">predict_log_proba</code><span class="sig-paren">(</span><em>X</em>, <em>num_threads=0</em><span class="sig-paren">)</span><a class="headerlink" href="#pai4sk.RandomForestClassifier.predict_log_proba" title="Permalink to this definition">¶</a></dt>
<dd><p>Log of probability estimates</p>
<p>The returned log-probability estimates for the two classes.
Only for binary classification.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>sparse matrix</em><em> (</em><em>csr_matrix</em><em>) or </em><em>dense matrix</em><em> (</em><em>ndarray</em><em>)</em>) – Dataset used for predicting log-probability estimates.</li>
<li><strong>num_threads</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>default : 0</em>) – Number of threads used to run inference.
By default inference runs with maximum number of available threads.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>proba</strong> – Returns the log-probability of the sample for each of the two classes.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">array-like, shape = (n_samples, 2)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="pai4sk.RandomForestClassifier.predict_proba">
<code class="descname">predict_proba</code><span class="sig-paren">(</span><em>X</em>, <em>num_threads=0</em><span class="sig-paren">)</span><a class="headerlink" href="#pai4sk.RandomForestClassifier.predict_proba" title="Permalink to this definition">¶</a></dt>
<dd><p>Probability estimates</p>
<p>The returned probability estimates for the two classes.
Only for binary classification.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>X</strong> (<em>sparse matrix</em><em> (</em><em>csr_matrix</em><em>) or </em><em>dense matrix</em><em> (</em><em>ndarray</em><em>)</em>) – Dataset used for predicting probability estimates.</li>
<li><strong>num_threads</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>default : 0</em>) – Number of threads used to run inferencei.
By default inference runs with maximum number of available threads.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>proba</strong> – Returns the probability of the sample of each of the two classes.</p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">array-like, shape = (n_samples, 2)</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li><a href="index.html">home</a>|&nbsp;</li>
        <li><a href="search.html">search</a>|&nbsp;</li>
 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2018, cdu.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.8.2.
    </div>
  </body>
</html>